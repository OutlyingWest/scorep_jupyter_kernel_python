{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Character Level GPT on Text Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the filename below to train the GPT model on the corpus. Select \"Run\" -> \"Run All\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scorep_env\n",
    "SCOREP_ENABLE_TRACING=1\n",
    "SCOREP_ENABLE_PROFILING=0\n",
    "SCOREP_TOTAL_MEMORY=3g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%env SCOREP_KERNEL_PERSISTENCE_MODE MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%switch_serializer\n",
    "cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scorep_python_binding_arguments\n",
    "--noinstrumenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"fairy_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%execute_with_scorep\n",
    "import scorep\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%d/%m/%Y %H:%M:%S\",\n",
    "    level=logging.INFO)\n",
    "\n",
    "from utils import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "import numpy as numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print(\"data has %d characters, %d unique.\" % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = {ch:i for i, ch in enumerate(chars)}\n",
    "        self.itos = {i:ch for i, ch in enumerate(chars)}\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.data[idx : idx+self.block_size+1]\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "\n",
    "        x = torch.tensor(dix[:-1], dtype = torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype = torch.long)\n",
    "        return x, y\n",
    "\n",
    "with scorep.instrumenter.enable():\n",
    "    block_size = 32\n",
    "\n",
    "    text = open(\"./{}\".format(filename), \"r\").read()\n",
    "    train_dataset = CharDataset(text, block_size)\n",
    "\n",
    "    from model import GPT, GPTconfig\n",
    "    mconf = GPTconfig(train_dataset.vocab_size, train_dataset.block_size,\n",
    "                      n_layer=1, n_head=8, n_embd=512)\n",
    "    model = GPT(mconf)\n",
    "\n",
    "    from trainer import Trainer, TrainerConfig\n",
    "\n",
    "    tconf = TrainerConfig(max_epochs=1, batch_size=512, learning_rate=6e-4,\n",
    "                          lr_decay=True, warmup_tokens=512*20, final_tokens=2*len(train_dataset)*block_size,\n",
    "                          num_workers=4)\n",
    "    trainer = Trainer(model, train_dataset, None, tconf)\n",
    "    trainer.train()\n",
    "\n",
    "    torch.save(model.state_dict(), \"./saved_models/trained_gpt_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "scorep-python",
   "language": "python",
   "name": "scorep-python"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/plain",
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
